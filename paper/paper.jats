<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">0</article-id>
<article-id pub-id-type="doi">N/A</article-id>
<title-group>
<article-title>SIRUS.jl: Interpretable Machine Learning via Rule
Extraction</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9445-8466</contrib-id>
<name>
<surname>Huijzer</surname>
<given-names>Rik</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6588-5079</contrib-id>
<name>
<surname>Blaauw</surname>
<given-names>Frank</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0094-8307</contrib-id>
<name>
<surname>den Hartigh</surname>
<given-names>Ruud J. R.</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0866-6929</contrib-id>
<name>
<surname>de Jonge</surname>
<given-names>Peter</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>University of Groningen, Groningen, the
Netherlands</institution>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Researchable, Assen, the Netherlands</institution>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2023-07-29">
<day>29</day>
<month>7</month>
<year>2023</year>
</pub-date>
<volume>¿VOL?</volume>
<issue>¿ISSUE?</issue>
<fpage>¿PAGE?</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>2022</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p><monospace>SIRUS.jl</monospace> is a pure Julia implementation of
  the original Stable and Interpretable RUle Sets (SIRUS) algorithm. The
  SIRUS algorithm is a fully interpretable version of random forests,
  that is, it reduces the large amount of trees in the forest to a small
  amount of interpretable rules. With our Julia implementation, we aimed
  to reproduce the original C++ and R implementation in a high-level
  language to verify the algorithm as well as making the code easier to
  read. Furthermore, we made the code available under the permissive MIT
  license. In turn, this allows others to research the algorithm further
  or easily port it to production environments.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>Due to the succesful applications of neural networks in various
  domains, there has been an paradigm shift within the field of machine
  learning towards the use of non-interpretable models, also known as
  “black box” models. This is appropriate for low stakes domains such as
  spam detection and product recommendations, but can be problematic in
  high stakes domains where model decisions have a real-world impact on
  individuals. In such situations, black box models may lead to unsafe
  or unreliable predictions
  (<xref alt="Barredo Arrieta et al., 2020" rid="ref-barredo2020explainable" ref-type="bibr">Barredo
  Arrieta et al., 2020</xref>;
  <xref alt="Doshi-Velez &amp; Kim, 2017" rid="ref-doshi2017towards" ref-type="bibr">Doshi-Velez
  &amp; Kim, 2017</xref>). However, the set of fully interpretable
  models is often limited to linear models and decision trees. Linear
  models tend to perform poorly when the data does not satisfy suitable
  distributions and decision trees perform poorly compared to random
  forests. Random forests
  (<xref alt="Breiman, 2001" rid="ref-breiman2001random" ref-type="bibr">Breiman,
  2001</xref>), often outperform linear models and random forests, but
  are not fully interpretable. Visualization techniques, such as SHAP
  (<xref alt="Lundberg &amp; Lee, 2017" rid="ref-lundberg2017unified" ref-type="bibr">Lundberg
  &amp; Lee, 2017</xref>), allow inspection of feature importances, but
  do not provide enough information to reproduce the predictions made by
  the model. The SIRUS algorithm solves these issues by first
  restricting the split points in the random forest algorithm to a
  stable subset of points, and by then extracting a small and
  interpretable rule set
  (<xref alt="Bénard et al., 2021" rid="ref-benard2021interpretable" ref-type="bibr">Bénard
  et al., 2021</xref>). However, the original SIRUS algorithm was
  implemented in C++ and R, which makes it hard to inspect and extend.
  An implementation in one high-level language allows verification of
  the algorithm and allows researchers to investigate further
  algorithmic improvements. Furthermore, the original algorithm was
  covered by a copyleft license meaning that copies are required to be
  made freely available. A more permissive license makes it easier to
  port the algorithm to other languages or move it to production
  environments.</p>
</sec>
<sec id="interpretability">
  <title>Interpretability</title>
  <p>To show that the algorithm is fully interpretable, we fitted the
  model on Haberman’s Survival Dataset
  (<xref alt="Haberman, 1999" rid="ref-haberman1999survival" ref-type="bibr">Haberman,
  1999</xref>). The dataset contains survival data on patients who had
  undergone surgery for breast cancer and contains three features,
  namely the number of auxillary <monospace>nodes</monospace> that were
  detected, the <monospace>age</monospace> of the patient at the time of
  the operation, and the patient’s <monospace>year</monospace> of
  operation.</p>
  <preformat>StableRules model with 8 rules:
 if X[i, :nodes] &lt; 8.0 then 0.156 else 0.031 +
 if X[i, :nodes] &lt; 14.0 then 0.164 else 0.026 +
 if X[i, :nodes] &lt; 4.0 then 0.128 else 0.037 +
 if X[i, :nodes] ≥ 8.0 &amp; X[i, :age] &lt; 38.0 then 0.0 else 0.008 +
 if X[i, :year] ≥ 1966.0 &amp; X[i, :age] &lt; 42.0 then 0.0 else 0.005 +
 if X[i, :nodes] &lt; 2.0 then 0.107 else 0.034 +
 if X[i, :year] ≥ 1966.0 &amp; X[i, :age] &lt; 38.0 then 0.0 else 0.001 +
 if X[i, :year] &lt; 1959.0 &amp; X[i, :nodes] ≥ 2.0 then 0.0 else 0.003
and 2 classes: [0.0, 1.0].
Note: showing only the probability for class 1.0 since class 0.0 has
      probability 1 - p.</preformat>
  <p>This shows that the model contains 8 rules. The first rule, for
  example, can be interpreted as: <italic>If the number of detected
  auxillary nodes is lower than 8, then take 0.156, otherwise take
  0.031.</italic></p>
  <p>This is done for all 8 rules and the total score is summed to get a
  prediction. In essence, the first rule says that if there are less
  than 8 auxillary nodes detected, then the patient will most likely
  survive (<monospace>class == 1.0</monospace>). In essence, the model
  states that if there are many auxillary nodes detected, then it is
  (unfortunately) less likely that the patient will survive.</p>
  <p>This model is fully interpretable because there are few rules which
  can all be interpreted in isolation reasonably well. Random forests,
  in contrasts, consist of hundreds to thousands of trees, which are not
  interpretable due to the large amount of trees. A common workaround
  for this is to use SHAP or Shapley values to visualize the fitted
  model. The problem with those methods is that they do not allow full
  reproducibility of the predictions. For example, if we would inspect
  the fitted model on the aforementioned Haberman dataset via SHAP, then
  we could learn feature importances. In practice that would mean that
  we could tell which features were important. In many real-world
  situations this is not enough. Imagine having to tell a patient that
  was misdiagnosed by the model: “Sorry about our prediction, we were
  wrong and we didn’t really know why. Only that nodes is an important
  feature in the model, but we don’t know whether this played a large
  role in your situation.”</p>
</sec>
<sec id="stability">
  <title>Stability</title>
  <p>Another problem that the SIRUS algorithm solves is that of model
  stability. A stable model is defined as a model which leads to similar
  conclusions for small changes to data (Yu, 2020). Unstable models can
  be difficult to apply in practice since they might require processes
  to constantly change. Also, they are considered less trustworthy.</p>
  <p>Having said that, most statistical models are quite stable since a
  higher stability is often correlated to a higher predictive
  performance. Put differently, an unstable model by definition leads to
  different conclusions for small changes to the data and, hence, small
  changes to the data can cause a sudden drop in predictive performance.
  One model which suffers from a low stability is a decision tree. This
  is because a decision tree will first create the root node of the
  tree, so a small change in the data can cause the root, and therefore
  the rest, of the tree to be completely different. The SIRUS algorithm
  has solved the instability of random forests by “stabilizing the
  trees”
  (<xref alt="Bénard et al., 2021" rid="ref-benard2021interpretable" ref-type="bibr">Bénard
  et al., 2021</xref>) and the authors have proven mathematically that
  the stabilization works.</p>
</sec>
<sec id="predictive-performance">
  <title>Predictive Performance</title>
  <p>The model is based on random forests and therefore has excellent
  performance in settings where the number of variables is comparatively
  large to the number of datapoints (Biau and Scornet). The algorithm
  converts a large number of trees to a small number of rules to improve
  interpretability. This tradeoff comes at a small performance cost. For
  example, the cross-validated scores on the Haberman dataset are listed
  in Table
  <xref alt="[tab:perf]" rid="tabU003Aperf">[tab:perf]</xref>.</p>
  <boxed-text id="tabU003Aperf">
    <table-wrap>
      <caption>
        <p>Predictive performance in terms of Area Under the Curve (AUC)
        score for the LightGBM, decision tree, and SIRUS models.</p>
      </caption>
      <table>
        <tbody>
          <tr>
            <td align="left"></td>
            <td align="center"><bold>AUC</bold></td>
            <td align="center"><bold>Interpret-</bold></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td align="left"><bold>Model</bold></td>
            <td align="center"><bold>1.96SE</bold></td>
            <td align="center"><bold>ability</bold></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td align="left"><monospace>LGBMClassifier()</monospace></td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[0.71 \pm 0.06]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn>0.71</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
            <td align="center">Medium</td>
            <td align="center"></td>
          </tr>
          <tr>
            <td align="left"><monospace>LGBMClassifier(; max_depth=2)</monospace></td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[0.67 \pm 0.06]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn>0.67</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
            <td align="center">Medium</td>
            <td align="center"></td>
          </tr>
          <tr>
            <td align="left"><monospace>DecisionTreeClassifier(; max_depth=2)</monospace></td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[0.63 \pm 0.06]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn>0.63</mml:mn><mml:mo>±</mml:mo><mml:mn>0.06</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
            <td align="center">High</td>
            <td align="center"></td>
          </tr>
          <tr>
            <td align="left"><monospace>StableRulesClassifier(; max_depth=2)</monospace></td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[\mathbf{0.71 \pm 0.05}]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn mathvariant="bold">0.71</mml:mn><mml:mo mathvariant="bold">±</mml:mo><mml:mn mathvariant="bold">0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
            <td align="center"><bold>High</bold></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td align="left"><monospace>StableRulesClassifier(; max_depth=2, max_rules=25)</monospace></td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[\mathbf{0.70 \pm 0.09}]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn mathvariant="bold">0.70</mml:mn><mml:mo mathvariant="bold">±</mml:mo><mml:mn mathvariant="bold">0.09</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
            <td align="center"><bold>High</bold></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td align="left"><monospace>StableRulesClassifier(; max_depth=2, max_rules=10)</monospace></td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[\mathbf{0.67 \pm 0.07}]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn mathvariant="bold">0.67</mml:mn><mml:mo mathvariant="bold">±</mml:mo><mml:mn mathvariant="bold">0.07</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
            <td align="center"><bold>High</bold></td>
            <td align="center"></td>
          </tr>
          <tr>
            <td align="left"><monospace>StableRulesClassifier(; max_depth=1, max_rules=25)</monospace></td>
            <td align="center"><inline-formula><alternatives>
            <tex-math><![CDATA[\mathbf{0.67 \pm 0.07}]]></tex-math>
            <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mn mathvariant="bold">0.67</mml:mn><mml:mo mathvariant="bold">±</mml:mo><mml:mn mathvariant="bold">0.07</mml:mn></mml:mrow></mml:math></alternatives></inline-formula></td>
            <td align="center"><bold>High</bold></td>
            <td align="center"></td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
  </boxed-text>
  <p>This shows that the SIRUS algorithm performs very comparable to the
  state-of-the-art LGBM classifier by Microsoft. The tree depths are set
  to at most 2 because rules which belong to a depth of 3 will (almost)
  never show up in the final model.</p>
</sec>
<sec id="code-example">
  <title>Code Example</title>
  <p>The model can be used via the <monospace>MLJ.jl</monospace>
  (<xref alt="Blaom et al., 2020" rid="ref-blaom2020mlj" ref-type="bibr">Blaom
  et al., 2020</xref>) machine learning interface. For example, this is
  the code used to fit the model on the full Haberman dataset: </p>
  <code language="julia">model = StableRulesClassifier(; max_depth=2, max_rules=8)
mach = machine(model, X, y)
fit!(mach)</code>
  <p>and model performance was estimated via cross-validation
  (<monospace>CV</monospace>): </p>
  <code language="julia">resampling = CV(; nfolds=10, shuffle=true)
evaluate(model, X, y; resampling, measure=auc)</code>
</sec>
<sec id="funding">
  <title>Funding</title>
  <p>This research was supported by the Ministry of Defence, the
  Netherlands.</p>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We thank Clément Bénard for his help in re-implementing the SIRUS
  algorithm. Furthermore, we thank Anthony Bloam and Dávid Hanák (Cursor
  Insight) for respectively doing code reviews and fixing a critical
  bug.</p>
</sec>
</body>
<back>
<ref-list>
  <ref id="ref-barredo2020explainable">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Barredo Arrieta</surname><given-names>Alejandro</given-names></name>
        <name><surname>Díaz-Rodríguez</surname><given-names>Natalia</given-names></name>
        <name><surname>Del Ser</surname><given-names>Javier</given-names></name>
        <name><surname>Bennetot</surname><given-names>Adrien</given-names></name>
        <name><surname>Tabik</surname><given-names>Siham</given-names></name>
        <name><surname>Barbado</surname><given-names>Alberto</given-names></name>
        <name><surname>García</surname><given-names>Salvador</given-names></name>
        <name><surname>Gil-López</surname><given-names>Sergio</given-names></name>
        <name><surname>Molina</surname><given-names>Daniel</given-names></name>
        <name><surname>Benjamins</surname><given-names>Richard</given-names></name>
        <name><surname>others</surname></name>
      </person-group>
      <article-title>Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI</article-title>
      <source>Information fusion</source>
      <publisher-name>Elsevier</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>58</volume>
      <pub-id pub-id-type="doi">10.1016/j.inffus.2019.12.012</pub-id>
      <fpage>82</fpage>
      <lpage>115</lpage>
    </element-citation>
  </ref>
  <ref id="ref-benard2021interpretable">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bénard</surname><given-names>Clément</given-names></name>
        <name><surname>Biau</surname><given-names>Gérard</given-names></name>
        <name><surname>Veiga</surname><given-names>Sébastien Da</given-names></name>
        <name><surname>Scornet</surname><given-names>Erwan</given-names></name>
      </person-group>
      <article-title>SIRUS: Stable and Interpretable RUle Set for classification</article-title>
      <source>Electronic Journal of Statistics</source>
      <publisher-name>Institute of Mathematical Statistics; Bernoulli Society</publisher-name>
      <year iso-8601-date="2021">2021</year>
      <volume>15</volume>
      <issue>1</issue>
      <uri>https://doi.org/10.1214/20-EJS1792</uri>
      <pub-id pub-id-type="doi">10.1214/20-EJS1792</pub-id>
      <fpage>427 </fpage>
      <lpage> 505</lpage>
    </element-citation>
  </ref>
  <ref id="ref-blaom2020mlj">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Blaom</surname><given-names>Anthony D.</given-names></name>
        <name><surname>Kiraly</surname><given-names>Franz</given-names></name>
        <name><surname>Lienart</surname><given-names>Thibaut</given-names></name>
        <name><surname>Simillides</surname><given-names>Yiannis</given-names></name>
        <name><surname>Arenas</surname><given-names>Diego</given-names></name>
        <name><surname>Vollmer</surname><given-names>Sebastian J.</given-names></name>
      </person-group>
      <article-title>MLJ: A julia package for composable machine learning</article-title>
      <source>Journal of Open Source Software</source>
      <publisher-name>The Open Journal</publisher-name>
      <year iso-8601-date="2020">2020</year>
      <volume>5</volume>
      <issue>55</issue>
      <pub-id pub-id-type="doi">10.21105/joss.02704</pub-id>
      <fpage>2704</fpage>
      <lpage></lpage>
    </element-citation>
  </ref>
  <ref id="ref-breiman2001random">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Breiman</surname><given-names>Leo</given-names></name>
      </person-group>
      <article-title>Random forests</article-title>
      <source>Machine learning</source>
      <publisher-name>Springer</publisher-name>
      <year iso-8601-date="2001">2001</year>
      <volume>45</volume>
      <pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id>
      <fpage>5</fpage>
      <lpage>32</lpage>
    </element-citation>
  </ref>
  <ref id="ref-doshi2017towards">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Doshi-Velez</surname><given-names>Finale</given-names></name>
        <name><surname>Kim</surname><given-names>Been</given-names></name>
      </person-group>
      <article-title>Towards a rigorous science of interpretable machine learning</article-title>
      <source>arXiv preprint arXiv:1702.08608</source>
      <year iso-8601-date="2017">2017</year>
      <pub-id pub-id-type="doi">10.48550/arXiv.1702.08608</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-haberman1999survival">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Haberman</surname><given-names>S</given-names></name>
      </person-group>
      <article-title>Habermanś Survival</article-title>
      <publisher-name>UCI Machine Learning Repository</publisher-name>
      <year iso-8601-date="1999">1999</year>
      <uri>https://doi.org/10.24432/C5XK51</uri>
      <pub-id pub-id-type="doi">10.24432/C5XK51</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-lundberg2017unified">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Lundberg</surname><given-names>Scott M</given-names></name>
        <name><surname>Lee</surname><given-names>Su-In</given-names></name>
      </person-group>
      <article-title>A unified approach to interpreting model predictions</article-title>
      <source>Advances in neural information processing systems</source>
      <year iso-8601-date="2017">2017</year>
      <volume>30</volume>
    </element-citation>
  </ref>
</ref-list>
</back>
</article>
